% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/scpi.R
\name{scpi}
\alias{scpi}
\title{Prediction Intervals for Synthetic Control Methods}
\usage{
scpi(
  data,
  w.constr = NULL,
  V = NULL,
  P = NULL,
  u.missp = TRUE,
  u.sigma = "HC1",
  u.order = 1,
  u.lags = 0,
  u.design = NULL,
  u.alpha = 0.05,
  e.method = "all",
  e.order = 1,
  e.lags = 0,
  e.design = NULL,
  e.alpha = 0.05,
  sims = 200,
  rho = NULL,
  rho.max = NULL,
  cores = NULL,
  plot = FALSE,
  plot.name = NULL,
  w.bounds = NULL,
  e.bounds = NULL,
  opt.list.est = NULL,
  opt.list.inf = NULL,
  save.data = NULL
)
}
\arguments{
\item{data}{a class `scpi_data' object, obtained by calling \code{\link{scdata}}.}

\item{w.constr}{a list specifying the constraint set the estimated weights of the donors must belong to.
\code{w.constr} can contain up to five elements:
\itemize{
\item `\code{p}', a scalar indicating the norm to be used (\code{p} should be one of "no norm", "L1", and "L2")
\item `\code{dir}', a string indicating whether the constraint on the norm is an equality ("==") or inequality ("<=")
\item `\code{Q}', a scalar defining the value of the constraint on the norm
\item `\code{lb}', a scalar defining the lower bound on the weights. It can be either 0 or \code{-Inf}.
\item `\code{name}', a character selecting one of the default proposals
See the \strong{Details} section for more.
}}

\item{V}{a weighting matrix to be used when minimizing
\deqn{(\mathbf{A}-\mathbf{B}\mathbf{w}-\mathbf{C}\mathbf{r})'\mathbf{V}(\mathbf{A}-\mathbf{B}\mathbf{w}-\mathbf{C}\mathbf{r})}}

\item{P}{a \eqn{T_1\times (J+K_1)} matrix containing the design matrix to be used to obtain the predicted.
post-intervention outcome of the synthetic control unit. \eqn{T_1} is the number of post-treatment periods,
\eqn{J} is the size of the donor pool, and \eqn{K_1} is the number of covariates used for adjustment in the outcome equation.}

\item{u.missp}{a logical indicating if misspecification should be taken into account when dealing with \eqn{\mathbf{u}}.}

\item{u.sigma}{a string specifying the type of variance-covariance estimator to be used when estimating
the conditional variance of \eqn{\mathbf{u}}.}

\item{u.order}{a scalar that sets the order of the polynomial in \eqn{\mathbf{B}} when predicting moments of \eqn{\mathbf{u}}.}

\item{u.lags}{a scalar that sets the number of lags of \eqn{\mathbf{B}} when predicting moments of \eqn{\mathbf{u}}.}

\item{u.design}{a matrix with the same number of rows of \eqn{\mathbf{A}} and \eqn{\mathbf{B}} and whose columns specify the design matrix
to be used when modeling the estimated pseudo-true residuals \eqn{\mathbf{u}}.}

\item{u.alpha}{a scalar specifying the confidence level for in-sample uncertainty.}

\item{e.method}{a string selecting the method to be used in quantifying out-of-sample uncertainty among:
"gaussian" which uses conditional subgaussian bounds; "ls" which specifies a location-scale model for \eqn{\mathbf{u}}; "qreg" which employs a
quantile regressions to get the conditional bounds; "all" uses each one of the previous methods.}

\item{e.order}{a scalar that sets the order of the polynomial in \eqn{\mathbf{B}} when predicting moments of \eqn{\mathbf{e}}.}

\item{e.lags}{a scalar that sets the number of lags of \eqn{\mathbf{B}} when predicting moments of \eqn{\mathbf{e}}.}

\item{e.design}{a matrix with the same number of rows of \eqn{\mathbf{A}} and \eqn{\mathbf{B}} and whose columns specify the design matrix
to be used when modeling the estimated out-of-sample residuals \eqn{\mathbf{e}}.}

\item{e.alpha}{a scalar specifying the confidence level for out-of-sample uncertainty.}

\item{sims}{a scalar providing the number of simulations to be used in quantifying in-sample uncertainty.}

\item{rho}{a string specifying the regularizing parameter that imposes sparsity on the estimated vector of weights. If
\code{rho = 'type-1'} (the default), then the tuning parameter is computed based on optimization inequalities. Users can provide a scalar
with their own value for \code{rho}. Other options are described in the \strong{Details} section.}

\item{rho.max}{a scalar indicating the maximum value attainable by the tuning parameter \code{rho}.}

\item{cores}{number of cores to be used by the command. The default is the number of cores available minus one.}

\item{plot}{a logical specifying whether \code{\link{scplot}} should be called and a plot saved in the current working directory. For more options see \code{\link{scplot}}.}

\item{plot.name}{a string containing the name of the plot (the format is by default .png). For more options see \code{\link{scplot}}.}

\item{w.bounds}{a \eqn{T_1\times 2} matrix with the user-provided bounds on \eqn{\beta}. If \code{w.bounds} is provided, then
the quantification of in-sample uncertainty is skipped. It is possible to provide only the lower bound or the upper bound
by filling the other column with \code{NA}s.}

\item{e.bounds}{a \eqn{T_1\times 2} matrix with the user-provided bounds on \eqn{\mathbf{e}}. If \code{e.bounds} is provided, then
the quantification of out-of-sample uncertainty is skipped. It is possible to provide only the lower bound or the upper bound
by filling the other column with \code{NA}s.}

\item{opt.list.est}{a list specifying the stopping criteria and the algorithm for the underlying optimizer \code{\link{nloptr}} for point estimation.
See the \strong{Details} section for more.}

\item{opt.list.inf}{similar to the previous one but for the optimizer used for inference purposes. See the \strong{Details} section for more.}

\item{save.data}{a character specifying the name and the path of the saved dataframe containing the processed data used to produce the plot.}
}
\value{
\item{data}{object containing used data as returned by \code{\link{scdata}} and some other values.}
\item{est.results}{object containing all the results from \code{\link{scest}}.}
\item{inference.results}{object containing all the inference-related results.}
}
\description{
The command constructs a counterfactual synthetic control unit as proposed in Cattaneo, Feng,
and Titiunik (2021). \code{\link{scpi}} returns the estimated post-treatment series for the synthetic unit through the
command \code{\link{scest}} and quantifies in-sample and out-of-sample uncertainty to provide confidence intervals
for each point estimate.
}
\details{
\itemize{
\item{\strong{Estimation of Weights.} \code{w.constr} specifies the constraint set on the weights. First, the element
\code{p} allows the user to choose between imposing a constraint on either the L1 (\code{p = "L1"})
or the L2 (\code{p = "L2"}) norm of the weights and imposing no constraint on the norm (\code{p = "no norm"}).
Second, \code{Q} specifies the value of the constraint on the norm of the weights.
Third, \code{lb} sets the lower bound of each component of the vector of weights.
Fourth, \code{dir} sets the direction of the constraint on the norm in case \code{p = "L1"}
or \code{p = "L2"}. If \code{dir = "=="}, then
\deqn{||\mathbf{w}||_p = Q,\:\:\: w_j \geq lb,\:\: j =1,\ldots,J}
If instead \code{dir = "<="}, then
\deqn{||\mathbf{w}||_p \leq Q,\:\:\: w_j \geq lb,\:\: j =1,\ldots,J}
If instead \code{dir = "NULL"} no constraint on the norm of the weights is imposed.

An alternative to specifying an ad-hoc constraint set on the weights would be
choosing among some popular types of constraints. This can be done by including the element
`\code{name}' in the list \code{w.constr}. The following are available options:
\itemize{
\item {If \code{name == "simplex"} (the default), then
\deqn{||\mathbf{w}||_1 = 1,\:\:\: w_j \geq 0,\:\: j =1,\ldots,J.}}

\item {If \code{name == "lasso"}, then
\deqn{||\mathbf{w}||_1 \leq Q,}
where \code{Q} is by default equal to 1 but it can be provided as an element of the list (eg. \code{w.constr =
list(name = "lasso", Q = 2)}).}

\item{If \code{name == "ridge"}, then
\deqn{||\mathbf{w}||_2 \leq Q,}
where \code{Q} is a tuning parameter that is by default computed as
\deqn{(J+KM) \widehat{\sigma}_u^{2}/||\widehat{\mathbf{w}}_{OLS}||_{2}^{2}}
where \eqn{J} is the number of donors and \eqn{KM} is the total number of covariates used for adjustment.
The user can provide \code{Q} as an element of the list (eg. \code{w.constr =
list(name = "ridge", Q = 1)}).}

\item{If \code{name == "ols"}, then the problem is unconstrained and the vector of weights
is estimated via ordinary least squares.}
}
}
\item{\strong{Regularization.} \code{rho} is estimated through the formula
\deqn{\varrho = \mathcal{C}\frac{\log (T_0)^c}{T_0^{1/2}}}
where \eqn{\mathcal{C} = \widehat{\sigma}_u / \min_j \widehat{\sigma}_{b_j}} if \code{rho = 'type-1'},
\eqn{\mathcal{C} = \max_{j}\widehat{\sigma}_{b_j}\widehat{\sigma}_{u} / \min_j \widehat{\sigma}_{b_j}^2} if \code{rho = 'type-2'}, and
\eqn{\mathcal{C} = \max_{j}\widehat{\sigma}_{b_ju} / \min_j \widehat{\sigma}_{b_j}^2} if \code{rho = 'type-3'},

\code{rho} defines a new sparse weight vector as
\deqn{\widehat{w}^\star_j = \mathbf{1}(\widehat{w}_j\geq \varrho)}
}

\item{\strong{In-sample uncertainty.} To quantify in-sample uncertainty it is necessary to model the pseudo-residuals \eqn{\mathbf{u}}.
First of all, estimation of the first moment of \eqn{\mathbf{u}} can be controlled through
the option \code{u.missp}. When \code{u.missp = FALSE}, then \eqn{\mathbf{E}[u\: |\: H]=0}. If instead \code{u.missp = TRUE},
then \eqn{\mathbf{E}[u\: |\: H]} is estimated using a linear regression of
\eqn{\widehat{\mathbf{u}}} on \eqn{H}. The default set of variables in \eqn{H} is composed of \eqn{\mathbf{B}} and \eqn{\mathbf{C}} and, if required,
with lags (\code{u.lags}) and polynomials (\code{u.order}) of \eqn{\mathbf{B}}. The option \code{u.design} allows the user to provide an
ad-hoc set of variables to form \eqn{H}. Regarding the second moment of \eqn{\mathbf{u}}, different estimators can be chosen:
HC0, HC1, HC2, HC3, and HC4 using the option \code{u.sigma}.}

\item{\strong{Out-of-sample uncertainty.} To quantify out-of-sample uncertainty it is necessary to model the out-of-sample residuals
\eqn{\mathbf{e}} and estimate relevant moments. By default, the design matrix used during estimation \eqn{H} is composed of \eqn{\mathbf{B}} and \eqn{\mathbf{C}} and, if required,
with lags (\code{e.lags}) and polynomials (\code{e.order}) of \eqn{\mathbf{B}}. The option \code{e.design} allows the user to provide an
ad-hoc set of variables to form \eqn{H}. Finally, the option \code{e.method} allows the user to select one of three
estimation methods: "gaussian" relies on conditional subgaussian bounds; "ls" estimates conditional bounds using a location-scale
model; "qreg" uses conditional quantile regression of the residuals \eqn{\mathbf{e}} on \eqn{H}.}

\item{\strong{Algorithm Options.} The default is a sequential quadratic programming (SQP) algorithm for nonlinearly constrained gradient-based optimization
(\code{algorithm = 'NLOPTR_LD_SLSQP'}) for all cases not involving the L1 norm.
For a complete list of algorithms see \href{https://nlopt.readthedocs.io/en/latest/NLopt_Algorithms/}{the official \code{nloptr} documentation}.
The other default values are \code{maxeval = 5000}, \code{ftol_res = 1.0e-8}, \code{ftol_abs = 1.0e-8}, \code{xtol_res = 1.0e-8}, \code{xtol_abs = 1.0e-8},
\code{tol_constraints_eq = 1.0e-8}, and \code{tol_constraints_ineq = 1.0e-8}. More information on the stopping criteria can be obtained running
\code{nloptr.print.options()} or \code{nloptr.get.default.options()}. If the optimization involves the L1 norm then \code{CVXR} is used for optimization.
More information on the stopping criteria can be obtained reading \href{https://cvxr.rbind.io/}{the official documentation}. }
}
}
\examples{

data <- scpi_germany

df <- scdata(df = data, id.var = "country", time.var = "year", 
             outcome.var = "gdp", period.pre = (1960:1990), 
             period.post = (1991:2013), unit.tr = "West Germany",
             unit.co = unique(data$country)[-7], constant = T,
             cointegrated.data = T)
             
result <- scpi(df, w.constr = list(name = "simplex", Q = 1))
result <- scpi(df, w.constr = list(lb = 0, dir = "==", p = "L1", Q = 1))
                           
}
\references{


\itemize{
\item{\href{https://economics.mit.edu/files/17847}{Abadie, A. (2021)}. Using synthetic controls: Feasibility, data requirements, and methodological aspects.
\emph{Journal of Economic Literature}, 59(2), 391-425.}
\item{\href{https://cattaneo.princeton.edu/papers/Cattaneo-Feng-Titiunik_2021_JASA.pdf}{Cattaneo, M. D., Feng, Y., & Titiunik, R.
(2021)}. Prediction intervals for synthetic control methods. \emph{Journal of the American Statistical Association}, 116(536), 1865-1880.}
\item{\href{https://nppackages.github.io/references/Cattaneo-Feng-Palomba-Titiunik_2022_scpi.pdf}{Cattaneo, M. D., Feng, Y., Palomba F., and Titiunik, R. (2022).}.
scpi - Uncertainty Quantification for Synthetic Control Estimators.}}
}
\seealso{
\code{\link{scdata}}, \code{\link{scest}}, \code{\link{scplot}}
}
\author{
\itemize{
\item{Matias Cattaneo, }{Princeton University}
\item{Yingjie Feng, }{Tsinghua University}
\item{Filippo Palomba, Princeton University (maintainer). \email{fpalomba@princeton.edu}.}
\item{Rocio Titiunik, Princeton University}}
}
